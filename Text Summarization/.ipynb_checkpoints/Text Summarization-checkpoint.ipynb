{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was published at https://github.com/duyvuleo/VNTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will implement some algorithms to apply in text summarization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Text Summarization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text summarization is the problem of creating a short, accurate, and fluent summary of a longer text document.\n",
    "\n",
    "Automatic text summarization methods are greatly needed to address the ever-growing amount of text data available online to both better help discover relevant information and to consume relevant information faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will we do in this tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will solve Text Summarization for Vietnamese newspapers, using some algorithms belows:\n",
    "1. Extractive Text Summarization\n",
    "    - Doc2Vec\n",
    "    - Text Rank\n",
    "2. Abstractive Text Summarization\n",
    "    - Google textsum\n",
    "\n",
    "\n",
    "We just implement \"**Single document summarization**\" problem in this tutorial, another problem called \"**Multi-document summarization**\" will be dicussed in another time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic idea\n",
    "The idea of using Doc2Vec algorithm for text summarization problem is described as follows:\n",
    "1. In all documents, we will extract sentences separately.\n",
    "2. Each sentence will be represented by a vector, via doc2vec model\n",
    "3. Use KMean algorithm to find out most featured sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_data(folder):\n",
    "    sentences = []\n",
    "    for path in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, path)\n",
    "        with open(file_path, 'r', encoding=\"utf-16\") as f:\n",
    "\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                sens = line.split('.')\n",
    "                for sen in sens:\n",
    "                    if len(sen) > 10:\n",
    "                        sen = gensim.utils.simple_preprocess(sen)\n",
    "                        sen = ' '.join(sen)\n",
    "                        sen = ViTokenizer.tokenize(sen)\n",
    "                        sentences.append(sen)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sens = test_doc.split('.')\n",
    "# for sen in sens:\n",
    "#     if len(sen) > 10:\n",
    "#         sen = gensim.utils.simple_preprocess(sen)\n",
    "#         sen = ' '.join(sen)\n",
    "#         sen = ViTokenizer.tokenize(sen)\n",
    "#         sentences.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiprocessing here, but we will not use it for easy in understanding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# sentences = []\n",
    "# train_paths = [os.path.join(dir_path, 'VNTC-master/Data/10Topics/Ver1.1/Train_Full'), \n",
    "#                os.path.join(dir_path, 'VNTC-master/Data/10Topics/Ver1.1/Test_Full'),\n",
    "#                os.path.join(dir_path, 'VNTC-master/Data/27Topics/Ver1.1/new train'),\n",
    "#                os.path.join(dir_path, 'VNTC-master/Data/27Topics/Ver1.1/new test')]\n",
    "\n",
    "# dirs = []\n",
    "# for path in train_paths:\n",
    "#     for p in os.listdir(path):\n",
    "#         dirs.append(os.path.join(path, p))\n",
    "\n",
    "# for d in tqdm(dirs):\n",
    "#     sens = get_data(d)\n",
    "#     sentences = sentences + sens\n",
    "\n",
    "# # with Pool(8) as pool:\n",
    "# #     pool.map(get_data, tqdm(dirs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(sentences, open('./sentences.pkl', 'wb'))\n",
    "sentences = pickle.load(open('./sentences.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ông đồ cuối_cùng trên đảo'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(sentences):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in tqdm(range(len(sentences))):\n",
    "        sen = sentences[i]\n",
    "        \n",
    "        words = sen.split(' ')\n",
    "        tagged_document = gensim.models.doc2vec.TaggedDocument(words, [i])\n",
    "        \n",
    "        corpus.append(tagged_document)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2385532/2385532 [00:34<00:00, 69769.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train_corpus = get_corpus(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_corpus = shuffle(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# max_epochs = 40\n",
    "\n",
    "# for epoch in tqdm(range(max_epochs)):\n",
    "#     print('iteration {0}'.format(epoch))\n",
    "model.train(train_corpus[:50000],\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    \n",
    "#     # decrease the learning rate\n",
    "#     model.alpha -= 0.0002\n",
    "#     # fix the learning rate, no decay\n",
    "#     model.min_alpha = model.alpha\n",
    "\n",
    "# %time model.train(train_corpus[:50000], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load('model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04828287,  0.25527653,  1.1613333 , -0.43151897, -0.9858117 ,\n",
       "        0.10932952,  0.20315444, -0.48530903,  0.24952224, -0.11833256,\n",
       "       -0.0337567 , -0.3887124 , -0.39426357,  0.4454976 ,  0.64964545,\n",
       "       -0.5074249 ,  0.2037328 ,  0.32153234, -0.62261915,  0.8188216 ,\n",
       "        0.5820815 , -0.09879603, -0.44826344,  0.1201525 ,  0.236654  ,\n",
       "        0.13032307, -0.46023956,  0.19788027, -0.34569028, -0.21599784,\n",
       "        0.42319658, -0.106575  , -0.24495657, -0.00839793, -0.11475623,\n",
       "       -0.5559897 , -0.12046688,  0.18673038, -0.16149993, -0.02872676,\n",
       "        0.42999822,  0.46070522,  0.50624824, -0.15866163, -0.11092521,\n",
       "        0.30938515,  0.23203233,  0.11736044, -0.7434822 , -0.78674805,\n",
       "        0.27668393,  0.25058967, -0.15513541,  0.05721006, -0.62895125,\n",
       "       -0.3618494 ,  0.48457113, -0.16074707,  0.32852057, -0.63208133,\n",
       "       -0.45503548, -0.373764  ,  0.6417061 , -0.15453526,  0.828889  ,\n",
       "        0.4040729 , -0.13313939,  0.20088702, -0.36382645,  0.3100666 ,\n",
       "        0.02355373,  0.5920582 , -0.2271741 , -0.30618507, -0.23971866,\n",
       "        0.91544545, -0.51666105, -0.05829609, -0.43708014,  0.35457942,\n",
       "        0.50872976, -0.24838248,  0.44898847,  0.11512683,  0.34157744,\n",
       "       -0.47279087, -0.02090802,  0.23195563, -0.14476988,  0.5966468 ,\n",
       "        0.25278485,  0.70205003, -0.16960798, -0.09220067,  1.387285  ,\n",
       "        0.5248568 ,  0.33318955, -0.33651793,  0.41348195, -0.94656795,\n",
       "       -0.56593996,  0.6216159 ,  0.3179036 ,  0.31106716,  0.14830516,\n",
       "        0.535672  ,  0.695546  ,  0.28968796,  0.4329898 , -0.6800865 ,\n",
       "       -0.6313374 ,  0.36142987,  0.3392832 , -0.3685879 ,  1.0465527 ,\n",
       "       -0.31610152,  0.26410806, -0.75767416, -0.0933219 , -0.10084625,\n",
       "        0.11192366, -0.63711953,  0.6878306 ,  0.20774055,  0.37814376,\n",
       "       -0.38910306, -0.29257646,  0.32447788,  1.4432929 ,  0.42116693,\n",
       "        0.10012217, -0.54671454,  0.15930349, -0.04576634,  0.11046711,\n",
       "        0.4345503 ,  0.5950319 ,  0.10390531,  0.00534402, -0.05976183,\n",
       "        1.0111569 ,  0.14526764,  0.0051693 , -0.55909073,  0.18523502,\n",
       "       -0.59934396,  0.24894848, -0.18078412,  0.5796731 , -0.44970104,\n",
       "        0.81793183, -0.5046711 , -0.16381589,  0.14662668,  0.21144816,\n",
       "        0.08799265, -0.25188333, -0.39610714, -0.46737796,  0.06498595,\n",
       "       -0.24232577,  0.08590741, -0.34991795, -0.7811069 ,  0.05049568,\n",
       "       -0.44203833, -0.04051779, -0.93674725,  0.7014623 ,  0.43860036,\n",
       "        1.0785912 ,  0.4614321 ,  0.9178922 ,  0.01267096,  0.08151802,\n",
       "       -0.21591717, -0.389159  , -0.4332839 ,  0.06478307, -0.549585  ,\n",
       "        0.24735504, -0.15430401, -0.10635387,  0.9497028 , -0.5208101 ,\n",
       "       -0.25834572,  0.5067593 , -0.3163417 , -0.45160556, -1.0110141 ,\n",
       "       -0.11357957,  0.3088588 ,  0.67771375,  0.5347725 , -0.08545431,\n",
       "       -0.6260072 ,  0.37074357,  0.3511689 ,  0.03659426, -0.5359085 ,\n",
       "       -0.22255394, -0.4841223 , -0.31908542,  0.6693267 , -0.43263623,\n",
       "        0.17883465,  0.76907945,  0.3865581 , -0.27964267,  0.5833102 ,\n",
       "        0.10791489,  0.4569784 , -0.0223736 ,  0.48295155, -0.00460218,\n",
       "       -0.47181183, -0.48191187,  0.1006198 , -0.30717742,  0.62139356,\n",
       "        0.28134045,  0.29010874, -0.26925838,  0.8383542 , -0.18886985,\n",
       "        0.18526816, -0.57650745, -0.59799755,  0.19990733,  0.22144596,\n",
       "        0.70591587, -0.76111233,  0.13711332, -0.7318054 ,  0.02516509,\n",
       "       -0.3590674 , -0.6440488 , -0.5580956 , -0.5993928 , -0.32801956,\n",
       "       -0.4644991 ,  0.89624447, -0.39741072, -0.52681875, -0.29390556,\n",
       "       -0.3324342 , -0.62701875,  0.12948091,  0.9591448 , -0.21732959,\n",
       "       -0.6216343 , -0.04387471, -0.22252487,  0.27053964,  0.17134936,\n",
       "        0.69296885,  0.39905074,  0.3307731 , -0.38610834,  0.05903669,\n",
       "        0.40507847, -0.53825825,  0.08011609, -0.27195254, -0.296355  ,\n",
       "        0.27324116,  0.5513492 ,  0.77330786, -0.6397054 , -0.24681841,\n",
       "        0.2817206 ,  0.37891504,  0.03597298,  0.42222285, -0.06389087,\n",
       "        0.39442137,  0.07020057, -0.24582939,  0.279675  ,  0.00950517,\n",
       "       -0.60586107, -1.0425315 , -0.2628614 ,  0.20990998,  0.25524455,\n",
       "       -0.27130723,  0.51966363, -0.14886895,  0.8109764 ,  0.258794  ,\n",
       "       -0.05932726, -0.10472207,  0.06371555,  0.04762143,  0.02594266,\n",
       "       -1.0294654 , -0.5873498 ,  0.60305655, -0.07507906, -0.3711069 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(train_corpus[100000].words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = '''Trong trận bán kết lượt về AFF Cup 2018 diễn ra trên sân vận động Mỹ Đình tối 6/12, đội tuyển Việt Nam đã vượt qua đội tuyển Philippines với tỉ số 2-1. Qua đó, nâng tổng tỉ số sau hai lượt trận bán kết là 4-2.\n",
    "\n",
    "Đội tuyển Việt Nam đã xuất sắc giành quyền vào chơi trận chung kết AFF Cup sau tròn 10 năm chờ đợi. Đối thủ của chúng ta là đội tuyển Malaysia.\n",
    "\n",
    "Hai cầu thủ ghi bàn thắng trên sân Mỹ Đình tối qua là Quang Hải và Công Phượng. Đáng chú ý, bàn thắng của Công Phượng được ghi chỉ sau vài phút anh được HLV Park Hang Seo tung vào sân thay người ở những phút cuối cùng của trận đấu.\n",
    "\n",
    "Bàn thắng của Công Phượng không khỏi khiến nhiều người nhớ đến pha bỏ lỡ “không tưởng” của cầu thủ này ở trận bán kết lượt đi trên sân của đội tuyển Philippines hôm 2/12.\n",
    "\n",
    "Trong trận đấu ấy, Công Phượng cũng được HLV trưởng người Hàn Quốc tung vào sân ở những phút cuối trận đấu. Anh thực hiện một pha đi bóng qua hàng loạt cầu thủ hậu vệ Philippines. Thế nhưng, khi đối mặt với khung thành rộng lớn, anh lại sút bóng chệch cột dọc.\n",
    "\n",
    "Sau tình huống bỏ lỡ ấy, cộng đồng mạng Việt Nam thi nhau chế ảnh Công Phượng. Họ cho rằng, Công Phượng không chỉ lừa qua hàng loạt hậu vệ Philippines mà còn lừa luôn cả hàng triệu fan hâm mộ đội nhà.\n",
    "\n",
    "Thắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 2\n",
    "\n",
    "Công Phượng đã không còn lừa người hâm mộ khi ghi bàn trong trận bán kết lượt về AFF Cup 2018.\n",
    "\n",
    "Chính vì vậy, trước trận đấu bán kết lượt về hôm qua, Công Phượng đã đăng tải một tấm hình lên mạng xã hội Facebook với tựa đề: “Ngày mai rồi đấy”.\n",
    "\n",
    "Dòng trạng thái ấy thể hiện quyết tâm của tiền đạo xứ Nghệ. Anh mong chờ được ra sân trong trận bán kết lượt về với Philippines để khẳng định mình và lấy lại niềm tin nơi người hâm mộ. Và cuối cùng, Công Phượng cũng đã làm được điều mình mong muốn.\n",
    "\n",
    "Thắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 3\n",
    "\n",
    "Status trước hôm bán kết thể hiện sự quyết tâm của Công Phương.\n",
    "\n",
    "Ngay sau trận bán kết lượt về kết thúc, Công Phượng lại tiếp tục đăng một status: “Lần này không lừa cả nhà nữa nhé. Thắng rồi bà con ơi”. Với bàn thắng ghi được ở những phút cuối trận đấu, Công Phượng đã giúp đội tuyển Việt Nam chắc chắn vào chơi trận chung kết AFF Cup 2018.\n",
    "\n",
    "Cũng sau trận đấu bán kết lượt về khi đội tuyển Việt Nam vượt qua đội tuyển Philippines, cầu thủ Văn Toàn đã chia sẻ trạng thái: “Trở lại thôi”. Dòng trạng thái này của Văn Toàn như một thông điệp gửi tới người hâm mộ rằng, anh đã bình phục chấn thương và sẵn sàng trở lại ở trận chung kết.\n",
    "\n",
    "Thắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 4\n",
    "\n",
    "Văn Toàn đăng status mang thông điệp đã bình phục chấn thương và sẵn sàng trở lại.\n",
    "\n",
    "Thắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 5\n",
    "\n",
    "Người hâm mộ động viên tinh thần khi biết Văn Toàn sắp trở lại.\n",
    "\n",
    "Trước đó, Văn Toàn đã bị chấn thương sụn chêm ở đầu gối sau một pha va chạm với đồng đội Văn Quyết trong buổi tập trước trận đấu với đội tuyển Campuchia ở vòng bảng AFF Cup 2018.\n",
    "\n",
    "Rất may, chấn thương của Văn Toàn không quá nặng và không phải phẫu thuật nên bình phục nhanh chóng. Ban đầu, các bác sĩ của đội tuyển Việt Nam dự đoán Văn Toàn có thể trở lại ở trận bán kết lượt về. Tuy nhiên, chấn thương chưa bình phục hẳn nên Văn Toàn phải đợi đến chung kết để có cơ hội được ra sân.\n",
    "\n",
    "Những cầu thủ khác như Nguyễn Quang Hải, Phan Văn Đức, Phạm Đức Huy cũng có những chia sẻ lên Facebook cá nhân sau trận đấu. Các cầu thủ thầm cảm ơn những người thân, người hâm mộ đã luôn bên họ và chứng kiến họ trưởng thành.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Vài ngày trở lại đây, dư luận thế giới hết sức quan tâm đến sự việc bà Meng Wanzhou - phó chủ tịch và giám đốc tài chính tập đoàn Huawei bị bắt giữ. \n",
    "\n",
    "Bà Meng sinh năm 1972, còn được biết đến với 2 cái tên khác là Sabrina Meng và Cathy Meng. Huawei là nhà cung cấp thiết bị viễn thông lớn nhất thế giới và là hãng smartphone thứ 2 thế giới.\n",
    "\n",
    "Bà Meng bị cơ quan chức năng Canada bắt giữ ở Vancouver hôm 1/12 trong khi quá cảnh trong một chuyến bay tại đây. Hiện, bà đang đối mặt với nguy cơ bị dẫn độ từ Canada đến Mỹ.\n",
    "\n",
    "Một số thông tin nói vụ bắt giữ có thể vì bà liên quan đến vi phạm các biện pháp trừng phạt của Mỹ đối với Iran.\n",
    "\n",
    "Người phụ nữ quyền lực của Huawei vừa bị bắt ở Canada là ai? - 1\n",
    "\n",
    "Chân dung bà Meng Wanzhou\n",
    "\n",
    "Tờ Bưu Điện Hoa Nam Buổi Sáng cho hay bà Meng đã nói trong một cuộc trao đổi nội bộ gần đây về tuân thủ quy định. Bà Meng nói có thể có những trường hợp \"quy định bên ngoài rõ ràng và không có tranh cãi nhưng công ty hoàn toàn không thể tuân thủ trong các hoạt động thực tế\".\n",
    "\n",
    "\"Trong những trường hợp như vậy, sau quá trình xem xét  hợp lý, công ty có thể chấp nhận rủi ro tạm thời không tuân thủ\", lời bà Meng được SCMP dẫn và Straittimes trích dẫn trong bài báo của tờ này.  Được biết, cuộc họp này có sự tham dự của cha bà là Ren Zhengfei - nhà sáng lập Huawei.\n",
    "\n",
    "Bà Meng được thăng chức vào tháng 3 năm nay, trở thành một trong 4 phó chủ tịch của tập đoàn Huawei. Mặc dù, hầu hết người Trung Quốc theo họ cha nhưng bà Meng lại theo họ mẹ.\n",
    "\n",
    "Từng bước vươn lên\n",
    "\n",
    "Sau khi tốt nghiệp đại học vào năm 1992, bà Meng làm việc một năm tại ngân hàng Xây dựng Trung Quốc trước khi làm việc tại công ty Huawei.\n",
    "\n",
    "Trong những năm đầu tiên ở Huawei, bà chủ yếu làm các công việc hành chính như nhận điện thoại, đánh máy... và là một trong 3 thư ký trong Huawei.\n",
    "\n",
    "Bà có bằng thạc sĩ kế toán từ Đại học Khoa học và Công nghệ Huazhong ở Vũ Hán, Hồ Bắc trước khi về Huawei làm người đứng đầu bộ phận tài chính của Huawei.\n",
    "\n",
    "Trong những năm qua, Meng là người đứng đầu bộ phận kế toán quốc tế, giám đốc tài chính Huawei Hong Kong và là chủ tịch bộ phận quản lý kế toán.\n",
    "\n",
    "Năm 2003, bà Meng thành lập tổ chức tài chính thống nhất toàn cầu của Huawei và phát triển cơ cấu tổ chức tiêu chuẩn hóa và thống nhất quy trình tài chính, hệ thống tài chính và nền tảng công nghệ thông tin.\n",
    "\n",
    "Người phụ nữ quyền lực của Huawei vừa bị bắt ở Canada là ai? - 2\n",
    "\n",
    "Từ năm 2005, bà Meng lãnh đạo việc thành lập 5 trung tâm dịch vụ được chia sẻ trên khắp thế giới và bà thúc đẩy hoàn thành Trung tâm thanh toán toàn cầu tại Thâm Quyến, Trung Quốc. Các trung tâm này đã nâng cao hiệu quả kế toán và chất lượng giám sát của Huawei, cung cấp các dịch vụ kế toán để duy trì sự mở rộng nhanh chóng của Huawei ở nước ngoài.\n",
    "\n",
    "Năm 2007, bà Meng phụ trách chương trình chuyển đổi dịch vụ tài chính tích hợp (IFS) - đây là sự hợp tác 8 năm giữa Huawei và IBM. Chương trình này giúp Huawei phát triển hệ thống dữ liệu, quy tắc phân bổ nguồn lực, cải thiện hiệu quả hoạt động, tối ưu hóa quy trình và kiểm soát nội bộ. IFS cũng giúp quản lý tài chính của Huawei lên một cấp mới.\n",
    "\n",
    "Công ty Huawei được cha của Meng Wanzhou là  Ren Zhengfei thành lập năm 1987 và phát triển thành tập đoàn hàng đầu thế giới về công nghệ.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trong trận bán kết lượt về AFF Cup 2018 diễn ra trên sân vận động Mỹ Đình tối 6/12, đội tuyển Việt Nam đã vượt qua đội tuyển Philippines với tỉ số 2-1. Qua đó, nâng tổng tỉ số sau hai lượt trận bán kết là 4-2.\\n\\nĐội tuyển Việt Nam đã xuất sắc giành quyền vào chơi trận chung kết AFF Cup sau tròn 10 năm chờ đợi. Đối thủ của chúng ta là đội tuyển Malaysia.\\n\\nHai cầu thủ ghi bàn thắng trên sân Mỹ Đình tối qua là Quang Hải và Công Phượng. Đáng chú ý, bàn thắng của Công Phượng được ghi chỉ sau vài phút anh được HLV Park Hang Seo tung vào sân thay người ở những phút cuối cùng của trận đấu.\\n\\nBàn thắng của Công Phượng không khỏi khiến nhiều người nhớ đến pha bỏ lỡ “không tưởng” của cầu thủ này ở trận bán kết lượt đi trên sân của đội tuyển Philippines hôm 2/12.\\n\\nTrong trận đấu ấy, Công Phượng cũng được HLV trưởng người Hàn Quốc tung vào sân ở những phút cuối trận đấu. Anh thực hiện một pha đi bóng qua hàng loạt cầu thủ hậu vệ Philippines. Thế nhưng, khi đối mặt với khung thành rộng lớn, anh lại sút bóng chệch cột dọc.\\n\\nSau tình huống bỏ lỡ ấy, cộng đồng mạng Việt Nam thi nhau chế ảnh Công Phượng. Họ cho rằng, Công Phượng không chỉ lừa qua hàng loạt hậu vệ Philippines mà còn lừa luôn cả hàng triệu fan hâm mộ đội nhà.\\n\\nThắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 2\\n\\nCông Phượng đã không còn lừa người hâm mộ khi ghi bàn trong trận bán kết lượt về AFF Cup 2018.\\n\\nChính vì vậy, trước trận đấu bán kết lượt về hôm qua, Công Phượng đã đăng tải một tấm hình lên mạng xã hội Facebook với tựa đề: “Ngày mai rồi đấy”.\\n\\nDòng trạng thái ấy thể hiện quyết tâm của tiền đạo xứ Nghệ. Anh mong chờ được ra sân trong trận bán kết lượt về với Philippines để khẳng định mình và lấy lại niềm tin nơi người hâm mộ. Và cuối cùng, Công Phượng cũng đã làm được điều mình mong muốn.\\n\\nThắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 3\\n\\nStatus trước hôm bán kết thể hiện sự quyết tâm của Công Phương.\\n\\nNgay sau trận bán kết lượt về kết thúc, Công Phượng lại tiếp tục đăng một status: “Lần này không lừa cả nhà nữa nhé. Thắng rồi bà con ơi”. Với bàn thắng ghi được ở những phút cuối trận đấu, Công Phượng đã giúp đội tuyển Việt Nam chắc chắn vào chơi trận chung kết AFF Cup 2018.\\n\\nCũng sau trận đấu bán kết lượt về khi đội tuyển Việt Nam vượt qua đội tuyển Philippines, cầu thủ Văn Toàn đã chia sẻ trạng thái: “Trở lại thôi”. Dòng trạng thái này của Văn Toàn như một thông điệp gửi tới người hâm mộ rằng, anh đã bình phục chấn thương và sẵn sàng trở lại ở trận chung kết.\\n\\nThắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 4\\n\\nVăn Toàn đăng status mang thông điệp đã bình phục chấn thương và sẵn sàng trở lại.\\n\\nThắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 5\\n\\nNgười hâm mộ động viên tinh thần khi biết Văn Toàn sắp trở lại.\\n\\nTrước đó, Văn Toàn đã bị chấn thương sụn chêm ở đầu gối sau một pha va chạm với đồng đội Văn Quyết trong buổi tập trước trận đấu với đội tuyển Campuchia ở vòng bảng AFF Cup 2018.\\n\\nRất may, chấn thương của Văn Toàn không quá nặng và không phải phẫu thuật nên bình phục nhanh chóng. Ban đầu, các bác sĩ của đội tuyển Việt Nam dự đoán Văn Toàn có thể trở lại ở trận bán kết lượt về. Tuy nhiên, chấn thương chưa bình phục hẳn nên Văn Toàn phải đợi đến chung kết để có cơ hội được ra sân.\\n\\nNhững cầu thủ khác như Nguyễn Quang Hải, Phan Văn Đức, Phạm Đức Huy cũng có những chia sẻ lên Facebook cá nhân sau trận đấu. Các cầu thủ thầm cảm ơn những người thân, người hâm mộ đã luôn bên họ và chứng kiến họ trưởng thành.\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_sentence_vectors_from_document(doc, model):\n",
    "    vectors = []\n",
    "    sens = doc.split('.')\n",
    "    for sen in sens:\n",
    "        if len(sen) > 10:\n",
    "            sen = gensim.utils.simple_preprocess(sen)\n",
    "            sen = ' '.join(sen)\n",
    "            sen = ViTokenizer.tokenize(sen)\n",
    "            sen = sen.split(' ')\n",
    "            vec = model.infer_vector(sen)\n",
    "            \n",
    "            vectors.append(vec)\n",
    "    \n",
    "    return np.array(vectors), sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_vectors, sens = get_list_sentence_vectors_from_document(test_doc, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 300)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sen_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=2, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "n_clusters = 2\n",
    "\n",
    "gm = GaussianMixture(2)\n",
    "gm.fit(X)\n",
    "# kmeans = KMeans(n_clusters=n_clusters)\n",
    "# kmeans = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07272727, 0.92727273])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Thắng bán kết AFF Cup 2018, Công Phượng hết &#34;lừa&#34; fan, Văn Toàn hứa hẹn trở lại - 5\n",
      "\n",
      "Người hâm mộ động viên tinh thần khi biết Văn Toàn sắp trở lại\n",
      "\n",
      "\n",
      "Hai cầu thủ ghi bàn thắng trên sân Mỹ Đình tối qua là Quang Hải và Công Phượng\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "avg = []\n",
    "for j in range(n_clusters):\n",
    "    idx = np.where(kmeans.labels_ == j)[0]\n",
    "    avg.append(np.mean(idx))\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X)\n",
    "ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "summary = [sens[closest[idx]] for idx in ordering]\n",
    "\n",
    "for sen in summary:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(links):\n",
    "    website_list = links.keys()\n",
    "    return {website: index for index, website in enumerate(website_list)}\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def build_transition_matrix(links, index):\n",
    "    total_links = 0\n",
    "    A = np.zeros((len(index), len(index)))\n",
    "    for webpage in links:\n",
    "        # dangling page\n",
    "        if not links[webpage]:\n",
    "            # Assign equal probabilities to transition to all the other pages\n",
    "            A[index[webpage]] = np.ones(len(index)) / len(index)\n",
    "        else:\n",
    "            for dest_webpage in links[webpage]:\n",
    "                total_links += 1\n",
    "                A[index[webpage]][index[dest_webpage]] = 1.0 / len(links[webpage])\n",
    " \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(A, eps=0.0001, d=0.85):\n",
    "    P = np.ones(len(A)) / len(A)\n",
    "    while True:\n",
    "        new_P = np.ones(len(A)) * (1 - d) / len(A) + d * A.T.dot(P)\n",
    "        delta = abs(new_P - P).sum()\n",
    "        if delta <= eps:\n",
    "            return new_P\n",
    "        P = new_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    " \n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stopwords=None):\n",
    "    # Create an empty similarity matrix\n",
    "    S = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    " \n",
    "            S[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    " \n",
    "    # normalize the matrix row-wise\n",
    "    for idx in range(len(S)):\n",
    "        S[idx] /= S[idx].sum()\n",
    " \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_sentences(doc):\n",
    "    sentences = []\n",
    "    sens = doc.split('.')\n",
    "    for sen in sens:\n",
    "        if len(sen) > 10:\n",
    "            sen = gensim.utils.simple_preprocess(sen)\n",
    "            sen = ' '.join(sen)\n",
    "            sen = ViTokenizer.tokenize(sen)\n",
    "            sen = sen.split(' ')\n",
    "#             print(sen)\n",
    "            sentences.append(sen)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_list_of_sentences(test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.04835242 0.07416923 0.03121135 0.06129788 0.00646136\n",
      "  0.05169091 0.01709516 0.02305111 0.01103488 0.02043263 0.01560568\n",
      "  0.06566879 0.03822594 0.         0.07173594 0.01152556 0.03188264\n",
      "  0.0325992  0.         0.07173594 0.10361859 0.0162996  0.0299869\n",
      "  0.02340851 0.05405965 0.         0.06129788 0.01854231 0.\n",
      "  0.00900994]\n",
      " [0.08017343 0.         0.05051936 0.04251838 0.08350444 0.01760428\n",
      "  0.05281285 0.         0.03140191 0.         0.02783481 0.02125919\n",
      "  0.06506095 0.04165934 0.         0.06514929 0.         0.04343286\n",
      "  0.088818   0.         0.02171643 0.08686572 0.0222045  0.02042517\n",
      "  0.02125919 0.036822   0.         0.05566963 0.         0.02328828\n",
      "  0.        ]\n",
      " [0.10692028 0.04392199 0.         0.02835152 0.         0.02347729\n",
      "  0.02347729 0.01552877 0.         0.         0.05568128 0.\n",
      "  0.06507457 0.01388935 0.         0.01448065 0.02093899 0.0289613\n",
      "  0.0296122  0.         0.14480651 0.0868839  0.0444183  0.04085889\n",
      "  0.02835152 0.06138284 0.         0.07424171 0.01684331 0.01552877\n",
      "  0.01636876]\n",
      " [0.08441652 0.06935524 0.05319304 0.         0.05861588 0.07414388\n",
      "  0.14828775 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.07310685 0.         0.         0.04573149\n",
      "  0.         0.         0.04573149 0.09146299 0.0467593  0.\n",
      "  0.         0.03877076 0.05319304 0.11723176 0.         0.\n",
      "  0.        ]\n",
      " [0.12580606 0.10336023 0.         0.04447916 0.         0.03683224\n",
      "  0.07366449 0.02436224 0.06570007 0.         0.02911845 0.02223958\n",
      "  0.03403065 0.         0.         0.04543581 0.03285004 0.02271791\n",
      "  0.         0.05447562 0.02271791 0.04543581 0.02322848 0.0427342\n",
      "  0.02223958 0.         0.02642456 0.         0.02642456 0.02436224\n",
      "  0.05136011]\n",
      " [0.00783818 0.01287945 0.01975617 0.03325459 0.02177024 0.\n",
      "  0.08261224 0.12750001 0.01228007 0.01175727 0.01088512 0.02494094\n",
      "  0.03816423 0.02443703 0.02715226 0.04246228 0.06140035 0.04246228\n",
      "  0.02604996 0.02036419 0.10190946 0.01698491 0.03473328 0.02396248\n",
      "  0.03325459 0.01439966 0.01975617 0.02177024 0.02963425 0.03642857\n",
      "  0.01919954]\n",
      " [0.0507572  0.03127597 0.01599172 0.05383614 0.03524403 0.06687084\n",
      "  0.         0.02948727 0.03976063 0.         0.01762201 0.02691807\n",
      "  0.05663571 0.02637422 0.03296777 0.04124553 0.01988031 0.0618683\n",
      "  0.04920127 0.01648389 0.04124553 0.04124553 0.04217251 0.02586205\n",
      "  0.03364759 0.01165587 0.03997929 0.05286604 0.01599172 0.00737182\n",
      "  0.01554116]\n",
      " [0.02422052 0.         0.01526198 0.         0.01681789 0.1489119\n",
      "  0.04254626 0.         0.         0.         0.01681789 0.02568974\n",
      "  0.05896506 0.05034141 0.02097559 0.05248455 0.07589253 0.02624227\n",
      "  0.02683206 0.         0.11809024 0.03936341 0.01341603 0.02468191\n",
      "  0.03853462 0.03337196 0.         0.         0.03052396 0.07035426\n",
      "  0.02966396]\n",
      " [0.06544794 0.05377097 0.         0.         0.09088952 0.02874179\n",
      "  0.11496717 0.         0.         0.04908595 0.         0.13883604\n",
      "  0.         0.03400775 0.         0.07091105 0.         0.\n",
      "  0.03625238 0.         0.         0.10636658 0.07250476 0.\n",
      "  0.         0.06011777 0.         0.         0.         0.03802182\n",
      "  0.04007851]\n",
      " [0.06318505 0.         0.         0.         0.         0.05549606\n",
      "  0.         0.         0.09899194 0.         0.         0.\n",
      "  0.05127483 0.06566382 0.         0.20537781 0.         0.\n",
      "  0.06999787 0.         0.06845927 0.06845927 0.06999787 0.\n",
      "  0.06701786 0.11607834 0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.07472763 0.06139502 0.14126348 0.         0.05188826 0.03281702\n",
      "  0.06563403 0.04341283 0.         0.         0.         0.\n",
      "  0.         0.03882962 0.06471603 0.         0.         0.\n",
      "  0.04139251 0.         0.08096535 0.12144802 0.         0.\n",
      "  0.         0.03432086 0.         0.10377652 0.         0.04341283\n",
      "  0.        ]\n",
      " [0.02649433 0.02176731 0.         0.         0.01839674 0.03490536\n",
      "  0.04654048 0.03078363 0.08301728 0.         0.         0.\n",
      "  0.12900132 0.02753372 0.         0.02870588 0.04150864 0.07176471\n",
      "  0.10272864 0.         0.02870588 0.02870588 0.02935104 0.06749758\n",
      "  0.08430445 0.         0.03338954 0.         0.         0.\n",
      "  0.06489759]\n",
      " [0.04988771 0.02980868 0.03429332 0.         0.01259647 0.02390011\n",
      "  0.04381687 0.03161688 0.         0.00680287 0.         0.05772426\n",
      "  0.         0.04241849 0.         0.03931052 0.03552683 0.0982763\n",
      "  0.06029102 0.01178291 0.05405197 0.03931052 0.03014551 0.09243279\n",
      "  0.10582781 0.02916123 0.01714666 0.03149116 0.00571555 0.\n",
      "  0.01666356]\n",
      " [0.05509241 0.03621043 0.01388607 0.         0.         0.02903293\n",
      "  0.03871058 0.05120928 0.01726264 0.01652772 0.0153017  0.02337373\n",
      "  0.08047375 0.         0.         0.0477529  0.05178793 0.05969112\n",
      "  0.0732392  0.02862686 0.05969112 0.05969112 0.02441307 0.04491351\n",
      "  0.0350606  0.07084786 0.         0.0153017  0.         0.03840696\n",
      "  0.01349483]\n",
      " [0.         0.         0.         0.10951667 0.         0.09068842\n",
      "  0.13603263 0.05998475 0.         0.         0.07169549 0.\n",
      "  0.         0.         0.         0.         0.         0.16780821\n",
      "  0.         0.         0.         0.05593607 0.17157965 0.\n",
      "  0.         0.         0.0650626  0.07169549 0.         0.\n",
      "  0.        ]\n",
      " [0.09096591 0.04982408 0.01273778 0.         0.02807269 0.04438682\n",
      "  0.05326418 0.04697459 0.03167026 0.04548295 0.         0.02144087\n",
      "  0.06561696 0.04201535 0.         0.         0.0475054  0.02190202\n",
      "  0.05598565 0.         0.03285303 0.04380403 0.05598565 0.02059972\n",
      "  0.03216131 0.02785251 0.01273778 0.02807269 0.0509511  0.\n",
      "  0.03713668]\n",
      " [0.01874811 0.         0.02362734 0.         0.02603606 0.08233326\n",
      "  0.0329333  0.08713333 0.         0.         0.         0.03977074\n",
      "  0.0760707  0.05845082 0.         0.06093919 0.         0.04062613\n",
      "  0.04153919 0.         0.08125225 0.04062613 0.04153919 0.07642099\n",
      "  0.03977074 0.01722124 0.02362734 0.         0.02362734 0.02178333\n",
      "  0.0459233 ]\n",
      " [0.03008991 0.02472138 0.01896043 0.01595758 0.01044669 0.03303533\n",
      "  0.0594636  0.01748066 0.         0.         0.         0.03989396\n",
      "  0.12209019 0.03908793 0.03908793 0.0163008  0.02357091 0.\n",
      "  0.05000145 0.01954397 0.04075199 0.03260159 0.02500073 0.11498662\n",
      "  0.11170308 0.03454918 0.01896043 0.05223345 0.00948022 0.\n",
      "  0.        ]\n",
      " [0.04137924 0.06799304 0.02607414 0.         0.         0.02725786\n",
      "  0.06360166 0.02403917 0.0162072  0.01551722 0.01436615 0.0768063\n",
      "  0.1007381  0.06450386 0.         0.0560416  0.03241441 0.06724992\n",
      "  0.         0.         0.03362496 0.04483328 0.03438067 0.06325124\n",
      "  0.04388932 0.01900463 0.02607414 0.0287323  0.         0.01201958\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.15025094 0.09502704\n",
      "  0.09502704 0.         0.         0.         0.         0.\n",
      "  0.08779895 0.11243751 0.         0.         0.         0.11722421\n",
      "  0.         0.         0.11722421 0.         0.         0.11025405\n",
      "  0.11475605 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.06613641 0.0120748  0.0926095  0.0155885  0.01020507 0.07745104\n",
      "  0.03872552 0.07684357 0.         0.01102274 0.02041014 0.0155885\n",
      "  0.06559651 0.03818388 0.         0.02388567 0.04605149 0.03980944\n",
      "  0.02442249 0.01909194 0.         0.04777133 0.02442249 0.04493084\n",
      "  0.03897125 0.04725014 0.         0.04082028 0.0185219  0.02561452\n",
      "  0.01800005]\n",
      " [0.09690691 0.04899517 0.05636637 0.03162625 0.02070424 0.01309451\n",
      "  0.03928353 0.02598361 0.0350363  0.01118157 0.03105636 0.01581312\n",
      "  0.04839398 0.03873408 0.01291136 0.03230646 0.02335753 0.03230646\n",
      "  0.03303254 0.         0.04845969 0.         0.03303254 0.03798189\n",
      "  0.03953281 0.0410837  0.00939439 0.07246483 0.00939439 0.04330602\n",
      "  0.01825942]\n",
      " [0.01930626 0.01586171 0.03649614 0.02047739 0.0134056  0.03391377\n",
      "  0.05087066 0.01121593 0.0302471  0.0144797  0.         0.02047739\n",
      "  0.04700126 0.02006366 0.05015915 0.05229452 0.0302471  0.03137671\n",
      "  0.0320819  0.         0.03137671 0.04183562 0.         0.08853316\n",
      "  0.05119346 0.03546787 0.0608269  0.05362238 0.04866152 0.01121593\n",
      "  0.0472905 ]\n",
      " [0.02824195 0.01160157 0.02669398 0.         0.01961023 0.01860389\n",
      "  0.02480519 0.01640709 0.         0.         0.         0.03744389\n",
      "  0.1145921  0.0293499  0.         0.01529969 0.04424664 0.11474769\n",
      "  0.04693064 0.01834369 0.04589907 0.03824923 0.07039597 0.\n",
      "  0.12730923 0.03242736 0.03559198 0.03922045 0.02669398 0.\n",
      "  0.01729459]\n",
      " [0.02412785 0.01321537 0.02027145 0.         0.01116902 0.02825564\n",
      "  0.03531955 0.02803402 0.         0.01206392 0.         0.05118289\n",
      "  0.14358528 0.02507439 0.         0.02614186 0.02520071 0.12199535\n",
      "  0.03563919 0.02089533 0.04356977 0.04356977 0.04454899 0.13932897\n",
      "  0.         0.02216284 0.01013572 0.04467609 0.01013572 0.\n",
      "  0.0197003 ]\n",
      " [0.08180302 0.03360402 0.06443277 0.0216913  0.         0.0179621\n",
      "  0.0179621  0.03564245 0.03204018 0.03067613 0.01420029 0.\n",
      "  0.05808545 0.07438567 0.         0.03323675 0.01602009 0.05539459\n",
      "  0.02265583 0.         0.07755242 0.0664735  0.04531165 0.05210082\n",
      "  0.03253695 0.         0.02577311 0.02840058 0.02577311 0.02376163\n",
      "  0.01252348]\n",
      " [0.         0.         0.         0.04525107 0.02962378 0.03747145\n",
      "  0.09367862 0.         0.         0.         0.         0.04525107\n",
      "  0.05193186 0.         0.03694735 0.02311216 0.03342013 0.04622433\n",
      "  0.04726321 0.         0.         0.02311216 0.11815802 0.08695165\n",
      "  0.02262554 0.03918858 0.         0.05924756 0.13441572 0.\n",
      "  0.02612572]\n",
      " [0.07841741 0.04295098 0.0658838  0.05544948 0.         0.02295827\n",
      "  0.0688748  0.         0.         0.         0.03630021 0.\n",
      "  0.05302995 0.01358229 0.02263716 0.02832104 0.         0.0708026\n",
      "  0.02895755 0.         0.05664208 0.09912364 0.05791509 0.05327414\n",
      "  0.05544948 0.02401033 0.0329419  0.         0.01647095 0.\n",
      "  0.01600689]\n",
      " [0.04802104 0.         0.03025931 0.         0.03334413 0.06326605\n",
      "  0.04217736 0.05579541 0.         0.         0.         0.\n",
      "  0.0194846  0.         0.         0.10405897 0.03761726 0.02601474\n",
      "  0.         0.         0.05202949 0.02601474 0.10639767 0.07340371\n",
      "  0.025467   0.04411014 0.15129654 0.03334413 0.         0.0278977\n",
      "  0.        ]\n",
      " [0.         0.04129804 0.03167415 0.         0.03490322 0.08829893\n",
      "  0.02207473 0.14601063 0.03937614 0.         0.03490322 0.\n",
      "  0.         0.07835753 0.         0.         0.03937614 0.\n",
      "  0.02784314 0.         0.08169337 0.13615562 0.02784314 0.\n",
      "  0.         0.04617262 0.         0.         0.03167415 0.\n",
      "  0.09234523]\n",
      " [0.02149638 0.         0.02709085 0.         0.05970534 0.03776097\n",
      "  0.03776097 0.04995307 0.03367835 0.         0.         0.09120141\n",
      "  0.0523331  0.02233969 0.         0.06987221 0.0673567  0.\n",
      "  0.         0.         0.04658148 0.04658148 0.09525676 0.04381174\n",
      "  0.0456007  0.01974568 0.02709085 0.02985267 0.         0.0749296\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "stop_words = []\n",
    "S = build_similarity_matrix(sentences, stop_words)    \n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. thắng bán_kết aff cup công phượng hết lừa fan văn_toàn hứa_hẹn trở_lại công phượng đã không còn lừa người hâm_mộ khi ghi_bàn trong trận bán_kết lượt về aff cup\n",
      "2. với bàn thắng ghi được những phút cuối trận_đấu công phượng đã giúp đội_tuyển việt nam chắc_chắn vào chơi trận chung_kết aff cup\n",
      "3. cũng sau trận_đấu bán_kết lượt về khi đội_tuyển việt nam vượt qua đội_tuyển philippines cầu_thủ văn_toàn đã chia_sẻ trạng_thái trở_lại thôi\n"
     ]
    }
   ],
   "source": [
    "def textrank(sentences, top_n=5, stopwords=None):\n",
    "    S = build_similarity_matrix(sentences, stop_words) \n",
    "    sentence_ranks = pagerank(S)\n",
    " \n",
    "    # Sort the sentence ranks\n",
    "    ranked_sentence_indexes = [item[0] for item in sorted(enumerate(sentence_ranks), key=lambda item: -item[1])]\n",
    "    selected_sentences = sorted(ranked_sentence_indexes[:top_n])\n",
    "    summary = itemgetter(*selected_sentences)(sentences)\n",
    "    return summary\n",
    " \n",
    "for idx, sentence in enumerate(textrank(sentences, top_n=3, stopwords=[])):\n",
    "    print(\"%s. %s\" % ((idx + 1), ' '.join(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
